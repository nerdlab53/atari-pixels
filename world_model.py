import torch
import torch.nn as nn

class WorldModel(nn.Module):
    """
    A recurrent world model that predicts the next latent state given the
    current latent state and an action.

    This model uses a GRU to understand the temporal and spatial dynamics of
    the latent space generated by the VQ-VAE. It learns the "physics" of the
    game at the latent level.
    """
    def __init__(self, n_actions, latent_dim, latent_seq_len, latent_vocab_size, hidden_size=512, n_gru_layers=2):
        super().__init__()
        self.n_actions = n_actions
        self.latent_dim = latent_dim
        self.latent_seq_len = latent_seq_len
        self.latent_vocab_size = latent_vocab_size
        self.hidden_size = hidden_size
        self.n_gru_layers = n_gru_layers

        # --- Embedding Layers ---
        # 1. An embedding for each of the 256 possible codes in the VQ-VAE codebook.
        self.latent_embedding = nn.Embedding(latent_vocab_size, latent_dim)
        # 2. An embedding for each of the 9 possible game actions.
        self.action_embedding = nn.Embedding(n_actions, latent_dim)

        # --- Recurrent Core ---
        # The GRU processes the sequence of latent codes, conditioned on the action.
        # It learns the spatial relationships within a frame and how they change.
        self.gru = nn.GRU(
            input_size=latent_dim,
            hidden_size=hidden_size,
            num_layers=n_gru_layers,
            batch_first=True
        )

        # --- Output Head ---
        # A fully-connected layer to predict the next latent code for each position
        # in the 5x7 grid. It maps the GRU's hidden state to logits over the vocab.
        self.output_fc = nn.Linear(hidden_size, latent_vocab_size)

    def forward(self, current_latent_codes, actions):
        """
        Forward pass: Predicts the next latent state.

        Args:
            current_latent_codes (torch.Tensor): Batch of current latent states.
                                                 Shape: (batch_size, latent_seq_len)
            actions (torch.Tensor): Batch of actions taken.
                                     Shape: (batch_size, 1)

        Returns:
            torch.Tensor: Logits for the predicted next latent state.
                          Shape: (batch_size, latent_seq_len, latent_vocab_size)
        """
        batch_size = current_latent_codes.size(0)

        # 1. Embed the inputs into dense vectors.
        latent_embeds = self.latent_embedding(current_latent_codes)
        # -> (batch_size, latent_seq_len, latent_dim)

        action_embeds = self.action_embedding(actions).unsqueeze(1).repeat(1, self.latent_seq_len, 1)
        # -> (batch_size, 1, latent_dim) -> (batch_size, latent_seq_len, latent_dim)

        # 2. Fuse the information by adding embeddings. The action provides context to the state.
        combined_input = latent_embeds + action_embeds

        # 3. Pass through the GRU to model the dynamics.
        # gru_out shape: (batch_size, latent_seq_len, hidden_size)
        gru_out, _ = self.gru(combined_input)

        # 4. Predict the next set of latent codes from the GRU's output.
        # output_logits shape: (batch_size, latent_seq_len, latent_vocab_size)
        output_logits = self.output_fc(gru_out)

        return output_logits 